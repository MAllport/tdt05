{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1\n",
    "## Team name: Team Hilbert Space\n",
    "### Michael Moen Allport & Jonas Sandberg\n",
    "### Student IDs: 768687 + 747903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/challenge1_train.csv') as train_csv:\n",
    "    df = pd.read_csv(train_csv, skipinitialspace=True)\n",
    "    \n",
    "labels = df['target']\n",
    "features = df.drop(columns=['target','id','f9'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features     = ['f2', 'f18']\n",
    "hexadecimal_features = ['f0', 'f7', 'f15', 'f23', 'f24']\n",
    "boolean_features     = ['f1', 'f10', 'f11', 'f13', 'f22']\n",
    "ordinal_features     = ['f4', 'f5', 'f6', 'f8', 'f12', 'f17', 'f19', 'f20']\n",
    "categorical_features = ['f3', 'f14', 'f16', 'f21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_hex(x):\n",
    "    try:\n",
    "        return int(x, 16)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "    except TypeError:\n",
    "        return np.nan\n",
    "\n",
    "for f in hexadecimal_features:\n",
    "    features[f] = features[f].apply(lambda x: conv_hex(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_pre, X_test_pre, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_transformer = make_pipeline(\n",
    "    IterativeImputer(random_state=0),\n",
    "    StandardScaler()\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "    OneHotEncoder(handle_unknown='ignore')\n",
    ")\n",
    "    \n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features + hexadecimal_features + boolean_features + ordinal_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    ")\n",
    "\n",
    "X_train = pd.DataFrame(preprocessor.fit_transform(X_train_pre, y_train))\n",
    "X_test  = pd.DataFrame(preprocessor.transform(X_test_pre))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_prob = model.predict_proba(X)[:,1]\n",
    "    \n",
    "    print(f\"AUC: {roc_auc_score(y, y_pred_prob)}\")\n",
    "    print(f\"F1: {f1_score(y, y_pred)}\")\n",
    "\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.744491390947271\n",
      "F1: 0.4368354658497026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78      8165\n",
      "           1       0.33      0.66      0.44      1835\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.61      0.68      0.61     10000\n",
      "weighted avg       0.80      0.69      0.72     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = make_pipeline(\n",
    "    RandomOverSampler(random_state=0),\n",
    "    AdaBoostClassifier(random_state=0, n_estimators=1000, learning_rate=1),\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model using all available training data\n",
    "This time we don't reserve any data for testing, to maximize the usage of available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7664749225634746\n",
      "F1: 0.45447747908136016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.69      0.79     40826\n",
      "           1       0.34      0.70      0.45      9174\n",
      "\n",
      "    accuracy                           0.69     50000\n",
      "   macro avg       0.62      0.69      0.62     50000\n",
      "weighted avg       0.81      0.69      0.73     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit preprocessor to all labeled data, and transform X\n",
    "X_all = pd.DataFrame(preprocessor.fit_transform(features, labels))\n",
    "y_all = labels\n",
    "\n",
    "# Read unlabeled data\n",
    "with open('datasets/challenge1_test.csv') as test_csv:\n",
    "    df_test = pd.read_csv(test_csv, skipinitialspace=True).drop(columns=['id', 'f9'])\n",
    "\n",
    "# Transform unlabeled data in the same way as training data\n",
    "for f in hexadecimal_features:\n",
    "    df_test[f] = df_test[f].apply(lambda x: conv_hex(x))\n",
    "\n",
    "X_unlabeled = pd.DataFrame(preprocessor.transform(df_test))\n",
    "\n",
    "# Fit our model on all labeled data\n",
    "model.fit(X_all, y_all)\n",
    "\n",
    "# Over-optimistic evaluation using training data for testing (not to be taken seriously)\n",
    "evaluate_model(model, X_all, y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_unlabeled)\n",
    "\n",
    "pd.DataFrame(y_pred[:, 1]).to_csv(\"predictions.txt\", header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MML] *",
   "language": "python",
   "name": "conda-env-MML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
